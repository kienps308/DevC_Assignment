{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of Week5_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofzy8xHIXdQF"
      },
      "source": [
        "[Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial/data)\n",
        "======\n",
        "\n",
        "## Data Set\n",
        "\n",
        "The labeled data set consists of 50,000 IMDB movie reviews, specially selected for sentiment analysis. The sentiment of reviews is binary, meaning the IMDB rating < 5 results in a sentiment score of 0, and rating >=7 have a sentiment score of 1. No individual movie has more than 30 reviews. The 25,000 review labeled training set does not include any of the same movies as the 25,000 review test set. In addition, there are another 50,000 IMDB reviews provided without any rating labels.\n",
        "\n",
        "## File descriptions\n",
        "\n",
        "labeledTrainData - The labeled training set. The file is tab-delimited and has a header row followed by 25,000 rows containing an id, sentiment, and text for each review.\n",
        "## Data fields\n",
        "\n",
        "* id - Unique ID of each review\n",
        "* sentiment - Sentiment of the review; 1 for positive reviews and 0 for negative reviews\n",
        "* review - Text of the review\n",
        "\n",
        "## Objective\n",
        "Objective of this dataset is base on **review** we predict **sentiment** (positive or negative) so X is **review** column and y is **sentiment** column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dub6uxUzXdQH"
      },
      "source": [
        "## 1. Load Dataset\n",
        "\n",
        "Let's first of all have a look at the data. You can download the file `labeledTrainData.tsv` on the [Kaggle website of the competition](https://www.kaggle.com/c/word2vec-nlp-tutorial/data), or on our [Google Drive](https://drive.google.com/file/d/1a1Lyn7ihikk3klAX26fgO3YsGdWHWoK5/view?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1WU9XkYXdQI"
      },
      "source": [
        "# Import pandas, numpy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj_BwmP9wQUe",
        "outputId": "069e6fa0-e616-4917-afaa-43ef9d5fccc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iH9rAw7XdQL"
      },
      "source": [
        "# Read dataset with extra params sep='\\t', encoding=\"latin-1\"\n",
        "df = pd.read_table('/content/drive/My Drive/DevCBtap/labeledTrainData.tsv', encoding=\"latin-1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXJVn2DtGU4U",
        "outputId": "d1012eea-2b7f-4294-dfef-c7f8e0d79be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5814_8</td>\n",
              "      <td>1</td>\n",
              "      <td>With all this stuff going down at the moment w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2381_9</td>\n",
              "      <td>1</td>\n",
              "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7759_3</td>\n",
              "      <td>0</td>\n",
              "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3630_4</td>\n",
              "      <td>0</td>\n",
              "      <td>It must be assumed that those who praised this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9495_8</td>\n",
              "      <td>1</td>\n",
              "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  sentiment                                             review\n",
              "0  5814_8          1  With all this stuff going down at the moment w...\n",
              "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
              "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
              "3  3630_4          0  It must be assumed that those who praised this...\n",
              "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zBUAUgxGp7Q"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Define an object of CountVectorizer() fit and transfom your twits into a 'bag'\n",
        "count = CountVectorizer()\n",
        "bag = count.fit_transform(df['review'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3USbAYsG9kw",
        "outputId": "3fd02a80-e581-49f5-e8b8-f4b4444f03d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "count.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '000',\n",
              " '0000000000001',\n",
              " '00001',\n",
              " '00015',\n",
              " '000s',\n",
              " '001',\n",
              " '003830',\n",
              " '006',\n",
              " '007',\n",
              " '0079',\n",
              " '0080',\n",
              " '0083',\n",
              " '0093638',\n",
              " '00am',\n",
              " '00pm',\n",
              " '00s',\n",
              " '01',\n",
              " '01pm',\n",
              " '02',\n",
              " '020410',\n",
              " '029',\n",
              " '03',\n",
              " '04',\n",
              " '041',\n",
              " '05',\n",
              " '050',\n",
              " '06',\n",
              " '06th',\n",
              " '07',\n",
              " '08',\n",
              " '087',\n",
              " '089',\n",
              " '08th',\n",
              " '09',\n",
              " '0f',\n",
              " '0ne',\n",
              " '0r',\n",
              " '0s',\n",
              " '10',\n",
              " '100',\n",
              " '1000',\n",
              " '1000000',\n",
              " '10000000000000',\n",
              " '1000lb',\n",
              " '1000s',\n",
              " '1001',\n",
              " '100b',\n",
              " '100k',\n",
              " '100m',\n",
              " '100min',\n",
              " '100mph',\n",
              " '100s',\n",
              " '100th',\n",
              " '100x',\n",
              " '100yards',\n",
              " '101',\n",
              " '101st',\n",
              " '102',\n",
              " '102nd',\n",
              " '103',\n",
              " '104',\n",
              " '1040',\n",
              " '1040a',\n",
              " '1040s',\n",
              " '105',\n",
              " '1050',\n",
              " '105lbs',\n",
              " '106',\n",
              " '106min',\n",
              " '107',\n",
              " '108',\n",
              " '109',\n",
              " '10am',\n",
              " '10lines',\n",
              " '10mil',\n",
              " '10min',\n",
              " '10minutes',\n",
              " '10p',\n",
              " '10pm',\n",
              " '10s',\n",
              " '10star',\n",
              " '10th',\n",
              " '10x',\n",
              " '10yr',\n",
              " '10â',\n",
              " '11',\n",
              " '110',\n",
              " '1100',\n",
              " '11001001',\n",
              " '1100ad',\n",
              " '111',\n",
              " '112',\n",
              " '1138',\n",
              " '114',\n",
              " '1146',\n",
              " '115',\n",
              " '116',\n",
              " '117',\n",
              " '11f',\n",
              " '11m',\n",
              " '11th',\n",
              " '12',\n",
              " '120',\n",
              " '1200',\n",
              " '1200f',\n",
              " '1201',\n",
              " '1202',\n",
              " '123',\n",
              " '12383499143743701',\n",
              " '125',\n",
              " '125m',\n",
              " '127',\n",
              " '128',\n",
              " '12a',\n",
              " '12hr',\n",
              " '12m',\n",
              " '12mm',\n",
              " '12s',\n",
              " '12th',\n",
              " '12â',\n",
              " '13',\n",
              " '130',\n",
              " '1300',\n",
              " '1300s',\n",
              " '131',\n",
              " '1318',\n",
              " '132',\n",
              " '134',\n",
              " '135',\n",
              " '135m',\n",
              " '136',\n",
              " '137',\n",
              " '138',\n",
              " '139',\n",
              " '13k',\n",
              " '13s',\n",
              " '13th',\n",
              " '14',\n",
              " '140',\n",
              " '1408',\n",
              " '140hp',\n",
              " '1415',\n",
              " '142',\n",
              " '145',\n",
              " '1454',\n",
              " '146',\n",
              " '147',\n",
              " '1473',\n",
              " '149',\n",
              " '1492',\n",
              " '14a',\n",
              " '14ieme',\n",
              " '14s',\n",
              " '14th',\n",
              " '14yr',\n",
              " '14ã',\n",
              " '15',\n",
              " '150',\n",
              " '1500',\n",
              " '1500s',\n",
              " '150_worst_cases_of_nepotism',\n",
              " '150k',\n",
              " '150m',\n",
              " '151',\n",
              " '152',\n",
              " '153',\n",
              " '1547',\n",
              " '155',\n",
              " '156',\n",
              " '1561',\n",
              " '157',\n",
              " '158',\n",
              " '1594',\n",
              " '15mins',\n",
              " '15minutes',\n",
              " '15s',\n",
              " '15th',\n",
              " '15â',\n",
              " '16',\n",
              " '160',\n",
              " '1600',\n",
              " '1600s',\n",
              " '160lbs',\n",
              " '161',\n",
              " '1610',\n",
              " '163',\n",
              " '164',\n",
              " '165',\n",
              " '166',\n",
              " '1660s',\n",
              " '168',\n",
              " '169',\n",
              " '1692',\n",
              " '16ieme',\n",
              " '16k',\n",
              " '16mm',\n",
              " '16s',\n",
              " '16th',\n",
              " '16x9',\n",
              " '16ã',\n",
              " '17',\n",
              " '170',\n",
              " '1700',\n",
              " '1700s',\n",
              " '1701',\n",
              " '171',\n",
              " '175',\n",
              " '177',\n",
              " '1775',\n",
              " '1780s',\n",
              " '1790s',\n",
              " '1794',\n",
              " '1798',\n",
              " '17million',\n",
              " '17th',\n",
              " '18',\n",
              " '180',\n",
              " '1800',\n",
              " '1800mph',\n",
              " '1800s',\n",
              " '1801',\n",
              " '1805',\n",
              " '1809',\n",
              " '180d',\n",
              " '1812',\n",
              " '1813',\n",
              " '18137',\n",
              " '1814',\n",
              " '1816',\n",
              " '1820',\n",
              " '1824',\n",
              " '183',\n",
              " '1830',\n",
              " '1832',\n",
              " '1836',\n",
              " '1837',\n",
              " '1838',\n",
              " '1839',\n",
              " '1840',\n",
              " '1840s',\n",
              " '1844',\n",
              " '1846',\n",
              " '1847',\n",
              " '185',\n",
              " '1850',\n",
              " '1850ies',\n",
              " '1850s',\n",
              " '1852',\n",
              " '1853',\n",
              " '1854',\n",
              " '1855',\n",
              " '1859',\n",
              " '1860',\n",
              " '1860s',\n",
              " '1861',\n",
              " '1862',\n",
              " '1863',\n",
              " '1864',\n",
              " '1865',\n",
              " '1870',\n",
              " '1870s',\n",
              " '1871',\n",
              " '1873',\n",
              " '1874',\n",
              " '1875',\n",
              " '1876',\n",
              " '188',\n",
              " '1880',\n",
              " '1880s',\n",
              " '1881',\n",
              " '1886',\n",
              " '1887',\n",
              " '1888',\n",
              " '1889',\n",
              " '188o',\n",
              " '1890',\n",
              " '1890s',\n",
              " '1892',\n",
              " '1893',\n",
              " '1894',\n",
              " '1895',\n",
              " '1896',\n",
              " '1897',\n",
              " '1898',\n",
              " '1899',\n",
              " '18a',\n",
              " '18s',\n",
              " '18th',\n",
              " '18year',\n",
              " '19',\n",
              " '190',\n",
              " '1900',\n",
              " '1900s',\n",
              " '1901',\n",
              " '1902',\n",
              " '1903',\n",
              " '1904',\n",
              " '1905',\n",
              " '1906',\n",
              " '1907',\n",
              " '1908',\n",
              " '1909',\n",
              " '1910',\n",
              " '1910s',\n",
              " '1911',\n",
              " '1912',\n",
              " '1913',\n",
              " '1914',\n",
              " '1915',\n",
              " '1916',\n",
              " '1917',\n",
              " '1918',\n",
              " '1919',\n",
              " '192',\n",
              " '1920',\n",
              " '1920ies',\n",
              " '1920s',\n",
              " '1921',\n",
              " '1922',\n",
              " '1923',\n",
              " '1924',\n",
              " '1925',\n",
              " '1926',\n",
              " '1927',\n",
              " '1928',\n",
              " '1929',\n",
              " '1930',\n",
              " '1930ies',\n",
              " '1930s',\n",
              " '1931',\n",
              " '1932',\n",
              " '1933',\n",
              " '1934',\n",
              " '1935',\n",
              " '1936',\n",
              " '1937',\n",
              " '1938',\n",
              " '1939',\n",
              " '193o',\n",
              " '194',\n",
              " '1940',\n",
              " '1940s',\n",
              " '1941',\n",
              " '1942',\n",
              " '1943',\n",
              " '1944',\n",
              " '1945',\n",
              " '1946',\n",
              " '1947',\n",
              " '1947â',\n",
              " '1948',\n",
              " '1949',\n",
              " '1949er',\n",
              " '195',\n",
              " '1950',\n",
              " '1950s',\n",
              " '1951',\n",
              " '1952',\n",
              " '1953',\n",
              " '1954',\n",
              " '1955',\n",
              " '1956',\n",
              " '1957',\n",
              " '1958',\n",
              " '1959',\n",
              " '1960',\n",
              " '1960s',\n",
              " '1961',\n",
              " '1961s',\n",
              " '1962',\n",
              " '1963',\n",
              " '1964',\n",
              " '1965',\n",
              " '1966',\n",
              " '1967',\n",
              " '1968',\n",
              " '1969',\n",
              " '197',\n",
              " '1970',\n",
              " '1970ies',\n",
              " '1970s',\n",
              " '1971',\n",
              " '1972',\n",
              " '1973',\n",
              " '1974',\n",
              " '1975',\n",
              " '1976',\n",
              " '1977',\n",
              " '1978',\n",
              " '1979',\n",
              " '19796',\n",
              " '197o',\n",
              " '1980',\n",
              " '1980ies',\n",
              " '1980s',\n",
              " '1981',\n",
              " '1982',\n",
              " '1982s',\n",
              " '1983',\n",
              " '1983s',\n",
              " '1984',\n",
              " '1984ish',\n",
              " '1985',\n",
              " '1986',\n",
              " '1987',\n",
              " '1988',\n",
              " '1988â',\n",
              " '1989',\n",
              " '1990',\n",
              " '1990s',\n",
              " '1991',\n",
              " '1992',\n",
              " '1993',\n",
              " '1994',\n",
              " '1995',\n",
              " '1996',\n",
              " '1997',\n",
              " '1998',\n",
              " '1999',\n",
              " '19k',\n",
              " '19th',\n",
              " '19thc',\n",
              " '1am',\n",
              " '1and',\n",
              " '1d',\n",
              " '1h',\n",
              " '1h30',\n",
              " '1h40',\n",
              " '1h40m',\n",
              " '1h53',\n",
              " '1hour',\n",
              " '1hr',\n",
              " '1million',\n",
              " '1min',\n",
              " '1mln',\n",
              " '1o',\n",
              " '1s',\n",
              " '1st',\n",
              " '1ton',\n",
              " '1tv',\n",
              " '1â',\n",
              " '1â½',\n",
              " '1ã',\n",
              " '20',\n",
              " '200',\n",
              " '2000',\n",
              " '20000',\n",
              " '20001',\n",
              " '2000ad',\n",
              " '2000s',\n",
              " '2000â',\n",
              " '2001',\n",
              " '2002',\n",
              " '2003',\n",
              " '2004',\n",
              " '2004s',\n",
              " '2005',\n",
              " '2006',\n",
              " '2007',\n",
              " '2007â',\n",
              " '2008',\n",
              " '2009',\n",
              " '200ft',\n",
              " '200th',\n",
              " '201',\n",
              " '2010',\n",
              " '2012',\n",
              " '2013',\n",
              " '2015',\n",
              " '2017',\n",
              " '2019',\n",
              " '2020',\n",
              " '2022',\n",
              " '2023',\n",
              " '2030',\n",
              " '2031',\n",
              " '2033',\n",
              " '2035',\n",
              " '2036',\n",
              " '2038',\n",
              " '204',\n",
              " '2040',\n",
              " '2044',\n",
              " '2046',\n",
              " '2047',\n",
              " '2050',\n",
              " '2053',\n",
              " '2054',\n",
              " '206',\n",
              " '2060',\n",
              " '2070',\n",
              " '2080',\n",
              " '209',\n",
              " '2090',\n",
              " '20c',\n",
              " '20ft',\n",
              " '20k',\n",
              " '20m',\n",
              " '20mins',\n",
              " '20minutes',\n",
              " '20mn',\n",
              " '20p',\n",
              " '20perr',\n",
              " '20s',\n",
              " '20th',\n",
              " '20ties',\n",
              " '20widow',\n",
              " '20x',\n",
              " '20year',\n",
              " '20yrs',\n",
              " '21',\n",
              " '210',\n",
              " '2100',\n",
              " '214',\n",
              " '215',\n",
              " '2151',\n",
              " '216',\n",
              " '21699',\n",
              " '21849889',\n",
              " '21849890',\n",
              " '21849907',\n",
              " '21st',\n",
              " '22',\n",
              " '220',\n",
              " '2200',\n",
              " '221',\n",
              " '2210',\n",
              " '22101',\n",
              " '222',\n",
              " '223',\n",
              " '225',\n",
              " '2257',\n",
              " '225mins',\n",
              " '227',\n",
              " '22d',\n",
              " '22h45',\n",
              " '22nd',\n",
              " '23',\n",
              " '230lbs',\n",
              " '230mph',\n",
              " '231',\n",
              " '232',\n",
              " '233',\n",
              " '236',\n",
              " '237',\n",
              " '23d',\n",
              " '23rd',\n",
              " '24',\n",
              " '240',\n",
              " '2400',\n",
              " '241',\n",
              " '242',\n",
              " '248',\n",
              " '2480',\n",
              " '249',\n",
              " '24m30s',\n",
              " '24th',\n",
              " '24years',\n",
              " '25',\n",
              " '250',\n",
              " '2500',\n",
              " '250000',\n",
              " '25million',\n",
              " '25mins',\n",
              " '25s',\n",
              " '25th',\n",
              " '25yo',\n",
              " '25yrs',\n",
              " '26',\n",
              " '260',\n",
              " '2600',\n",
              " '261k',\n",
              " '262',\n",
              " '2642',\n",
              " '269',\n",
              " '26th',\n",
              " '27',\n",
              " '270',\n",
              " '272',\n",
              " '273',\n",
              " '274',\n",
              " '275',\n",
              " '2772',\n",
              " '278',\n",
              " '27th',\n",
              " '27x41',\n",
              " '28',\n",
              " '280',\n",
              " '285',\n",
              " '28th',\n",
              " '29',\n",
              " '29th',\n",
              " '2am',\n",
              " '2d',\n",
              " '2fast',\n",
              " '2furious',\n",
              " '2h',\n",
              " '2h30',\n",
              " '2hour',\n",
              " '2hours',\n",
              " '2hr',\n",
              " '2hrs',\n",
              " '2in',\n",
              " '2inch',\n",
              " '2k',\n",
              " '2more',\n",
              " '2nd',\n",
              " '2oo4',\n",
              " '2oo5',\n",
              " '2pac',\n",
              " '2point4',\n",
              " '2s',\n",
              " '2x4',\n",
              " '2â',\n",
              " '30',\n",
              " '300',\n",
              " '3000',\n",
              " '300ad',\n",
              " '300c',\n",
              " '300lbs',\n",
              " '300mln',\n",
              " '3012',\n",
              " '303',\n",
              " '305',\n",
              " '30am',\n",
              " '30ish',\n",
              " '30k',\n",
              " '30lbs',\n",
              " '30min',\n",
              " '30mins',\n",
              " '30pm',\n",
              " '30s',\n",
              " '30something',\n",
              " '30th',\n",
              " '30ties',\n",
              " '31',\n",
              " '3199',\n",
              " '31st',\n",
              " '32',\n",
              " '3200',\n",
              " '320x180',\n",
              " '32lb',\n",
              " '32nd',\n",
              " '33',\n",
              " '330am',\n",
              " '330mins',\n",
              " '332960073452',\n",
              " '336th',\n",
              " '33m',\n",
              " '34',\n",
              " '345',\n",
              " '3462',\n",
              " '34th',\n",
              " '35',\n",
              " '350',\n",
              " '3500',\n",
              " '3516',\n",
              " '356',\n",
              " '357',\n",
              " '35c',\n",
              " '35mins',\n",
              " '35mm',\n",
              " '35pm',\n",
              " '35th',\n",
              " '35yr',\n",
              " '35â',\n",
              " '36',\n",
              " '360',\n",
              " '365',\n",
              " '36th',\n",
              " '37',\n",
              " '370',\n",
              " '372',\n",
              " '378',\n",
              " '38',\n",
              " '38k',\n",
              " '38th',\n",
              " '39',\n",
              " '395',\n",
              " '39th',\n",
              " '3am',\n",
              " '3bs',\n",
              " '3d',\n",
              " '3dvd',\n",
              " '3k',\n",
              " '3lbs',\n",
              " '3m',\n",
              " '3mins',\n",
              " '3p',\n",
              " '3p0',\n",
              " '3pm',\n",
              " '3po',\n",
              " '3rd',\n",
              " '3rds',\n",
              " '3th',\n",
              " '3who',\n",
              " '3x5',\n",
              " '3yrs',\n",
              " '3â',\n",
              " '40',\n",
              " '400',\n",
              " '4000',\n",
              " '401k',\n",
              " '405',\n",
              " '409',\n",
              " '40am',\n",
              " '40min',\n",
              " '40mins',\n",
              " '40mph',\n",
              " '40s',\n",
              " '40th',\n",
              " '41',\n",
              " '42',\n",
              " '420',\n",
              " '425',\n",
              " '428',\n",
              " '42nd',\n",
              " '43',\n",
              " '430',\n",
              " '44',\n",
              " '440',\n",
              " '442nd',\n",
              " '44c',\n",
              " '44yrs',\n",
              " '45',\n",
              " '450',\n",
              " '4500',\n",
              " '451',\n",
              " '454',\n",
              " '45am',\n",
              " '45min',\n",
              " '45mins',\n",
              " '45s',\n",
              " '46',\n",
              " '465',\n",
              " '469',\n",
              " '47',\n",
              " '475',\n",
              " '477',\n",
              " '47s',\n",
              " '48',\n",
              " '480m',\n",
              " '480p',\n",
              " '48hrs',\n",
              " '49',\n",
              " '498',\n",
              " '49th',\n",
              " '4am',\n",
              " '4cylinder',\n",
              " '4d',\n",
              " '4eva',\n",
              " '4ever',\n",
              " '4f',\n",
              " '4h',\n",
              " '4hrs',\n",
              " '4k',\n",
              " '4kids',\n",
              " '4m',\n",
              " '4o',\n",
              " '4pm',\n",
              " '4th',\n",
              " '4w',\n",
              " '4ward',\n",
              " '4x',\n",
              " '4x4',\n",
              " '4â',\n",
              " '50',\n",
              " '500',\n",
              " '5000',\n",
              " '500000',\n",
              " '500ad',\n",
              " '500db',\n",
              " '500lbs',\n",
              " '502',\n",
              " '50c',\n",
              " '50ft',\n",
              " '50ies',\n",
              " '50ish',\n",
              " '50k',\n",
              " '50min',\n",
              " '50mins',\n",
              " '50s',\n",
              " '50th',\n",
              " '50usd',\n",
              " '50â',\n",
              " '51',\n",
              " '51b',\n",
              " '51st',\n",
              " '52',\n",
              " '5200',\n",
              " '5250',\n",
              " '529',\n",
              " '52s',\n",
              " '53',\n",
              " '53m',\n",
              " '54',\n",
              " '5400',\n",
              " '540i',\n",
              " '54th',\n",
              " '55',\n",
              " '5539',\n",
              " '555',\n",
              " '55th',\n",
              " '56',\n",
              " '57',\n",
              " '571',\n",
              " '576',\n",
              " '578',\n",
              " '57d',\n",
              " '58',\n",
              " '58th',\n",
              " '59',\n",
              " '598947',\n",
              " '59th',\n",
              " '5hrs',\n",
              " '5ive',\n",
              " '5kph',\n",
              " '5million',\n",
              " '5min',\n",
              " '5mins',\n",
              " '5s',\n",
              " '5seconds',\n",
              " '5th',\n",
              " '5x',\n",
              " '5x5',\n",
              " '5years',\n",
              " '5yo',\n",
              " '5yrs',\n",
              " '5â',\n",
              " '60',\n",
              " '600',\n",
              " '6000',\n",
              " '607',\n",
              " '608',\n",
              " '60ies',\n",
              " '60ish',\n",
              " '60mph',\n",
              " '60s',\n",
              " '60th',\n",
              " '60ties',\n",
              " '60â',\n",
              " '61',\n",
              " '618',\n",
              " '62',\n",
              " '6200',\n",
              " '62229249',\n",
              " '63',\n",
              " '637',\n",
              " '63rd',\n",
              " '64',\n",
              " '65',\n",
              " '65m',\n",
              " '66',\n",
              " '660',\n",
              " '666',\n",
              " '66er',\n",
              " '67',\n",
              " '6723',\n",
              " '67th',\n",
              " '68',\n",
              " '68th',\n",
              " '69',\n",
              " '69th',\n",
              " '6am',\n",
              " '6b',\n",
              " '6ft',\n",
              " '6hours',\n",
              " '6k',\n",
              " '6million',\n",
              " '6pm',\n",
              " '6th',\n",
              " '6wks',\n",
              " '6yo',\n",
              " '70',\n",
              " '700',\n",
              " '701',\n",
              " '707',\n",
              " '70ies',\n",
              " '70m',\n",
              " '70mm',\n",
              " '70s',\n",
              " '70th',\n",
              " '70â',\n",
              " '71',\n",
              " '713',\n",
              " '72',\n",
              " '72nd',\n",
              " '73',\n",
              " '7300',\n",
              " '735',\n",
              " '737',\n",
              " '74',\n",
              " '740',\n",
              " '740il',\n",
              " '747',\n",
              " '747s',\n",
              " '74th',\n",
              " '75',\n",
              " '750',\n",
              " '75054',\n",
              " '75c',\n",
              " '75m',\n",
              " '76',\n",
              " '7600',\n",
              " '77',\n",
              " '78',\n",
              " '788',\n",
              " '78rpm',\n",
              " '79',\n",
              " '79th',\n",
              " '7days',\n",
              " '7even',\n",
              " '7eventy',\n",
              " '7ft',\n",
              " '7ish',\n",
              " '7mm',\n",
              " '7th',\n",
              " '7â',\n",
              " '7â½th',\n",
              " '80',\n",
              " '800',\n",
              " '8000',\n",
              " '80ies',\n",
              " '80ish',\n",
              " '80min',\n",
              " '80s',\n",
              " '80yr',\n",
              " '81',\n",
              " '817',\n",
              " '819',\n",
              " '82',\n",
              " '820',\n",
              " '8217',\n",
              " '8230',\n",
              " '83',\n",
              " '84',\n",
              " '849',\n",
              " '84f',\n",
              " '84s',\n",
              " '85',\n",
              " '850',\n",
              " '850pm',\n",
              " '86',\n",
              " '86s',\n",
              " '87',\n",
              " '8700',\n",
              " '8763',\n",
              " '878',\n",
              " '87minutes',\n",
              " '88',\n",
              " '88min',\n",
              " '89',\n",
              " '89or',\n",
              " '89s',\n",
              " '8bit',\n",
              " '8ftdf',\n",
              " '8k',\n",
              " '8mm',\n",
              " '8o',\n",
              " '8p',\n",
              " '8pm',\n",
              " '8star',\n",
              " '8th',\n",
              " '8u',\n",
              " '8â½',\n",
              " '90',\n",
              " '900',\n",
              " '9000',\n",
              " '90210',\n",
              " '905',\n",
              " '90c',\n",
              " '90ish',\n",
              " '90min',\n",
              " '90mins',\n",
              " '90s',\n",
              " '91',\n",
              " '911',\n",
              " '914',\n",
              " '917',\n",
              " '92',\n",
              " '921',\n",
              " '92fs',\n",
              " '92nd',\n",
              " '93',\n",
              " '937',\n",
              " '94',\n",
              " '9484',\n",
              " '94s',\n",
              " '94th',\n",
              " '95',\n",
              " '950',\n",
              " '95th',\n",
              " '96',\n",
              " '97',\n",
              " '970',\n",
              " '974th',\n",
              " '978',\n",
              " '98',\n",
              " '987',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7bzaqpYHgMF",
        "outputId": "260b309d-621e-4d4d-ecb9-bda02a7227de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "# Feed the tf-idf Vectorizer with twits using fit_transform()\n",
        "tfidf_vec = tfidf.fit_transform(df)\n",
        "\n",
        "# Formatting the number to 2 digits after the decimal point by showing on this notebook\n",
        "np.set_printoptions(precision=2)\n",
        "# To print array in one line\n",
        "np.set_printoptions(linewidth=np.inf)\n",
        "print(tfidf.get_feature_names())\n",
        "print(tfidf_vec.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['id', 'review', 'sentiment']\n",
            "[[1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbuaIdhWXdQO"
      },
      "source": [
        "## 2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6huK5U2Hl6N",
        "outputId": "05e08910-25dc-4fb8-aa35-5e3fd75b2bfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "vocab = Counter()\n",
        "for twit in df.review:\n",
        "    for word in twit.split(' '):\n",
        "        vocab[word] += 1\n",
        "\n",
        "vocab.most_common(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 287025),\n",
              " ('a', 155092),\n",
              " ('and', 152651),\n",
              " ('of', 142970),\n",
              " ('to', 132568),\n",
              " ('is', 103227),\n",
              " ('in', 85576),\n",
              " ('I', 65971),\n",
              " ('that', 64555),\n",
              " ('this', 57195),\n",
              " ('it', 54416),\n",
              " ('/><br', 50935),\n",
              " ('was', 46697),\n",
              " ('as', 42509),\n",
              " ('with', 41718),\n",
              " ('for', 41067),\n",
              " ('but', 33783),\n",
              " ('The', 33760),\n",
              " ('on', 30765),\n",
              " ('movie', 30496)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJr6juwHXdQP",
        "outputId": "10e065ab-9d78-4a10-e8b7-4c94f5ebe81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# stop words\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EVWBOVedym_",
        "outputId": "68c9af35-e862-4c14-eb57-398a5c070d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "vocab_reduced = Counter()\n",
        "# Go through all of the items of vocab using vocab.items() and pick only words that are not in 'stop_words' \n",
        "# and save them in vocab_reduced\n",
        "for w, c in vocab.items():\n",
        "    if not w in stop_words:\n",
        "        vocab_reduced[w]=c\n",
        "\n",
        "vocab_reduced.most_common(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 65971),\n",
              " ('/><br', 50935),\n",
              " ('The', 33760),\n",
              " ('movie', 30496),\n",
              " ('film', 27394),\n",
              " ('one', 20685),\n",
              " ('like', 18133),\n",
              " ('This', 12279),\n",
              " ('would', 11922),\n",
              " ('good', 11435),\n",
              " ('It', 10950),\n",
              " ('really', 10814),\n",
              " ('even', 10605),\n",
              " ('see', 10154),\n",
              " ('-', 9355),\n",
              " ('get', 8776),\n",
              " ('story', 8523),\n",
              " ('much', 8506),\n",
              " ('time', 7762),\n",
              " ('make', 7485)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v220Tp_XdQS",
        "outputId": "f960c274-e9f2-4dd7-bdac-7d346d2323ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Removing special characters and \"trash\"\n",
        "import re\n",
        "def preprocessor(text):\n",
        "    # Remove HTML markup\n",
        "    # Your code here\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    # Save emoticons for later appending\n",
        "    # Your code here\n",
        "    emoticons = re.findall('((?::|;|=)(?:-)?(?:\\)|(?i)\\(|D|P|O)\\s)', text)\n",
        "    # Remove any non-word character and append the emoticons,\n",
        "    # removing the nose character for standarization. Convert to lower case\n",
        "    # Your code here\n",
        "    #text = (re.sub('(((?::|;|=)(?:-)?(?:\\)|(?i)\\(|D|P|O)\\s)|[\\W])', ' ', text.lower()))\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower())  + ' '.join(emoticons).replace('-', ''))#extra character when emoticon with word next to word\n",
        "    return text\n",
        "preprocessor('hello[]:Dsasdfasdfasfd :D ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hello dsasdfasdfasfd d :D '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o5ED67LXdQV",
        "outputId": "ec7653de-600e-4851-ccc1-17e89b440014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# tokenizer and stemming\n",
        "# tokenizer: to break down our twits in individual words\n",
        "# stemming: reducing a word to its root\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "# Split a text into list of words\n",
        "def tokenizer(text): \n",
        "    return text.split()\n",
        "\n",
        "# Split a text into list of words and apply stemming technic\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "print(tokenizer('Hi there, I am loving this, like with a lot of love'))\n",
        "print(tokenizer_porter('Hi there, I am loving this, like with a lot of love'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hi', 'there,', 'I', 'am', 'loving', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n",
            "['Hi', 'there,', 'I', 'am', 'love', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjzOxu4MXdQZ"
      },
      "source": [
        "# split the dataset in train and test\n",
        "# Your code here\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['review']\n",
        "y = df['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COr1xR7PXdQc"
      },
      "source": [
        "## 3. Create Model and Train \n",
        "\n",
        "Using **Pipeline** to concat **tfidf** step and **LogisticRegression** step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOpwINJmXdQd",
        "outputId": "4ba4bb7c-adbc-4110-af34-d995ca0bfe89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Import Pipeline, LogisticRegression, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=stop_words,\n",
        "                        tokenizer=tokenizer_porter,\n",
        "                        preprocessor=preprocessor)\n",
        "\n",
        "# A pipeline is what chains several steps together, once the initial exploration is done. \n",
        "# For example, some codes are meant to transform features — normalise numericals, or turn text into vectors, \n",
        "# or fill up missing data, they are transformers; other codes are meant to predict variables by fitting an algorithm,\n",
        "# they are estimators. Pipeline chains all these together which can then be applied to training data\n",
        "clf = Pipeline([('vect', tfidf),\n",
        "                ('clf', LogisticRegression(random_state=0))])\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=<function preprocessor at 0x7f355265aa60>,\n",
              "                                 smooth_idf=True,\n",
              "                                 stop_words=['i', 'me', 'my', 'myself', '...\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenizer_porter at 0x7f35526d1048>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('clf',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=0,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYdoVMx_XdQf"
      },
      "source": [
        "## 4. Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2ZOzHoaXdQg",
        "outputId": "c32ae88c-579d-477a-c7bd-f2374a311ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Using Test dataset to evaluate model\n",
        "# classification_report\n",
        "# confusion matrix\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Now apply those above metrics to evaluate your model\n",
        "# Your code here\n",
        "predictions = clf.predict(X_test)\n",
        "print('accuracy:',accuracy_score(y_test,predictions))\n",
        "print('confusion matrix:\\n',confusion_matrix(y_test,predictions))\n",
        "print('classification report:\\n',classification_report(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.8854\n",
            "confusion matrix:\n",
            " [[2165  338]\n",
            " [ 235 2262]]\n",
            "classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88      2503\n",
            "           1       0.87      0.91      0.89      2497\n",
            "\n",
            "    accuracy                           0.89      5000\n",
            "   macro avg       0.89      0.89      0.89      5000\n",
            "weighted avg       0.89      0.89      0.89      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJh00BdefCbR",
        "outputId": "31736556-b8aa-4710-90a8-095fdd720555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "twits = [\n",
        "    \"I do not feel not bad\", # Phuc +1\n",
        "    'This model is \"so good\" :))', # Long -1\n",
        "    'we are who we are', # Nghi 0\n",
        "    'its good to be bad sometimes', # PA +1\n",
        "    'what a wonderful failure! (sarcasm :)))', #Phuc +1\n",
        "    'People do not like the bad things', # Chi 0\n",
        "    'sad', # Long +1\n",
        "]\n",
        "\n",
        "preds = clf.predict_proba(twits)\n",
        "\n",
        "for i in range(len(twits)):\n",
        "    print(f'{twits[i]} --> Negative, Positive = {preds[i]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I do not feel not bad --> Negative, Positive = [0.98 0.02]\n",
            "This model is \"so good\" :)) --> Negative, Positive = [0.52 0.48]\n",
            "we are who we are --> Negative, Positive = [0.49 0.51]\n",
            "its good to be bad sometimes --> Negative, Positive = [0.77 0.23]\n",
            "what a wonderful failure! (sarcasm :))) --> Negative, Positive = [0.5 0.5]\n",
            "People do not like the bad things --> Negative, Positive = [0.97 0.03]\n",
            "sad --> Negative, Positive = [0.58 0.42]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_zY7-l8fFIW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCAuLC0aXdQi"
      },
      "source": [
        "## 5. Export Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYHo_x67XdQj"
      },
      "source": [
        "# Using pickle to export our trained model\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "pickle.dump(clf, open('logisticRegression.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBVw6tVofMRX",
        "outputId": "35455d1f-cafb-4bbf-9e95-5b00c63024dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "with open('logisticRegression.pkl', 'rb') as model:\n",
        "    reload_model = pickle.load(model)\n",
        "preds = reload_model.predict_proba(twits)\n",
        "\n",
        "for i in range(len(twits)):\n",
        "    print(f'{twits[i]} --> Negative, Positive = {preds[i]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I do not feel not bad --> Negative, Positive = [0.98 0.02]\n",
            "This model is \"so good\" :)) --> Negative, Positive = [0.52 0.48]\n",
            "we are who we are --> Negative, Positive = [0.49 0.51]\n",
            "its good to be bad sometimes --> Negative, Positive = [0.77 0.23]\n",
            "what a wonderful failure! (sarcasm :))) --> Negative, Positive = [0.5 0.5]\n",
            "People do not like the bad things --> Negative, Positive = [0.97 0.03]\n",
            "sad --> Negative, Positive = [0.58 0.42]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}